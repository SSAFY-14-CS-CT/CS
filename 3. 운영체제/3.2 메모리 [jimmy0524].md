## **1. 메모리 계층 (Memory Hierarchy)**

- **구성**: 레지스터 → 캐시(L1, L2, L3) → 주기억장치(RAM) → 보조기억장치(HDD, SSD)
- **특징**:
    - 위로 갈수록 **속도 ↑, 가격 ↑, 용량 ↓**
    - CPU와 메모리 속도 차이 극복을 위해 다단계 계층 구조 사용

---

## **2. 캐시 (Cache)**

- **정의**: 느린 장치와 빠른 장치 사이 속도 차를 줄이기 위한 임시 저장소
- **지역성(Locality) 원리**
    - **시간 지역성**: 최근 접근 데이터가 다시 사용될 가능성 높음 (ex: 반복문에서 변수 i)
    - **공간 지역성**: 접근한 데이터 근처 데이터도 사용될 가능성 높음 (ex: 배열 연속 접근)
- **캐시 히트/미스**
    - 캐시 히트: 원하는 데이터가 캐시에 존재
    - 캐시 미스: 캐시에 없어 주 메모리에서 불러옴
- **캐시 매핑 방식**
    1. 직접 매핑 (Direct Mapping) – 간단, 충돌이 많음
    2. 연관 매핑 (Associative Mapping) – 유연, 검색 느림
    3. 집합 연관 매핑 (Set-Associative Mapping) – 위 두가지 매핑의 절충안, 가장 많이 사용됨

---

## **3. 가상 메모리 (Virtual Memory)**

- **정의**: 실제 메모리 크기보다 더 큰 메모리를 제공하는 추상화
- **주소 체계**
    - 가상 주소(Logical Address) ↔ 실제 주소(Physical Address)
    - 변환 담당: **MMU (Memory Management Unit)**
- **구조**
    - 페이지(Page): 가상 메모리 최소 단위
    - 프레임(Frame): 실제 메모리 최소 단위
    - 페이지 테이블: 매핑 정보 저장
    - TLB: 주소 변환 캐시 (변환 속도 향상)

---

## **4. 페이징 & 스와핑**

- **페이지 폴트(Page Fault)**: 프로세스가 요청한 데이터가 RAM에 없을 때 발생
- **스와핑(Swapping)**: 사용하지 않는 메모리 영역을 디스크로 내리고 필요한 페이지를 가져옴
- **문제**: 페이지 폴트가 잦으면 CPU 이용률↓ → 스레싱 발생

---

## **5. 스레싱 (Thrashing)**

- **정의**: 페이지 폴트율이 급격히 증가하여 CPU가 대부분 스와핑만 하게 되는 현상
- **원인**: 메모리에 너무 많은 프로세스를 동시에 올림
- **해결책**
    - 메모리 증설
    - 작업 세트(Working Set) 관리 → 자주 쓰는 페이지만 유지
    - PFF(Page Fault Frequency) 제어 → 상/하한선 기반으로 프레임 조정

---

## **6. 메모리 할당 기법**

### **1. 연속 할당**

- 고정 분할 방식: 메모리를 미리 고정된 크기로 나눔 → 내부 단편화 발생
- 가변 분할 방식: 프로그램 크기에 맞게 동적 할당 → 외부 단편화 발생
    - 최초적합(First Fit) / 최적적합(Best Fit) / 최악적합(Worst Fit)

> 단편화 문제
>
- 내부 단편화: 블록 크기 > 프로그램 크기 → 블록 내부 낭비
- 외부 단편화: 총 메모리는 충분하지만 연속 공간 부족 → 배치 불가

### **2. 불연속 할당**

- **페이징(Paging)**: 메모리를 동일 크기 페이지로 나눔, 외부 단편화 해결
- **세그멘테이션(Segmentation)**: 의미 단위(코드, 데이터, 스택 등)로 분할, 공유·보안 유리
- **페이징 + 세그멘테이션**: 보완적 결합 방식

---

## **7. 페이지 교체 알고리즘**

- 메모리가 가득 찼을 때 어떤 페이지를 교체할지 결정
- **종류**
    - **Optimal (OPT)**: 미래 참조를 기준으로 교체 (이론적 최적, 비교 기준)
    - **FIFO**: 가장 오래된 페이지 교체
    - **LRU (Least Recently Used)**: 가장 오래 사용되지 않은 페이지 교체 (지역성 반영)
    - **NUR (Not Used Recently, Clock Algorithm)**: 최근 사용 여부 비트 기반 교체
    - **LFU (Least Frequently Used)**: 사용 횟수 가장 적은 페이지 교체

---

# **❓면접 예상 질문 & 답변**

### **Q1. 메모리 계층 구조가 필요한 이유는 무엇인가요?**

**A1.** CPU와 메모리 속도 차이가 매우 크기 때문에 이를 완화하기 위해 다단계 메모리 계층 구조를 둡니다. 레지스터/캐시처럼 빠른 계층은 속도 향상에 기여하고, RAM/디스크는 용량 확보에 기여합니다.

---

### **Q2. 캐시에서 지역성(Locality) 원리란 무엇인가요?**

**A2.**

- 시간 지역성: 최근에 접근한 데이터가 다시 사용될 가능성이 높음
- 공간 지역성: 접근한 데이터 근처 데이터도 곧 사용될 가능성이 높음

  캐시는 이 원리를 활용해 성능을 높입니다.


---

### **Q3. 내부 단편화와 외부 단편화 차이는 무엇인가요?**

**A3.**

- 내부 단편화: 블록 크기 > 프로그램 크기 → 블록 내부 낭비
- 외부 단편화: 총 메모리 공간은 충분하지만 연속된 블록이 없어 할당 불가

  해결책으로는 페이징 기법(외부 단편화 제거)이 있습니다.


---

### **Q4. 페이지 폴트(Page Fault)는 언제 발생하나요?**

**A4.** 프로세스가 요구한 페이지가 현재 물리 메모리(RAM)에 없을 때 발생합니다. 운영체제가 스와핑을 통해 디스크에서 해당 페이지를 가져와 메모리에 적재 후 실행을 이어갑니다.

---

### **Q5. 스레싱(Thrashing)이란 무엇이며, 해결 방법은 무엇인가요?**

**A5.** 스레싱은 페이지 폴트가 과도하게 발생해 CPU가 대부분 스와핑만 하며 성능이 급격히 저하되는 현상입니다.

해결책:

1. 물리 메모리 증설
2. 작업 세트 기반 관리
3. PFF 제어 방식

---

### **Q6. 페이지 교체 알고리즘 중 LRU와 FIFO의 차이는 무엇인가요?**

**A6.**

- FIFO: 먼저 들어온 페이지를 먼저 내보냄 → 성능 예측 어려움 (Belady’s anomaly 발생)
- LRU: 가장 오래 참조되지 않은 페이지 교체 → 지역성 원리를 잘 반영해 일반적으로 성능이 좋음

---

### **Q7. 페이징과 세그멘테이션의 장단점을 설명해주세요.**

**A7.**

- 페이징: 고정 크기 단위라 외부 단편화 없음, 주소 변환 복잡
- 세그멘테이션: 의미 단위라 보안/공유 유리, 외부 단편화 가능
- 결합 방식(페이징+세그멘테이션): 장점 결합해 성능/보안/효율 개선