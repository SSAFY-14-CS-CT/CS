# 3.2 메모리

# **메모리 계층 구조**

| **구분** | **예시** | **속도** | **용량** | **휘발성 여부** | **특징** |
| --- | --- | --- | --- | --- | --- |
| **레지스터** | PC, IR, SP 등 | 가장 빠름 | 매우 적음 | 휘발성 | CPU 내부의 초고속 임시기억장치 |
| **캐시(Cache)** | L1, L2, L3 | 매우 빠름 | 적음 | 휘발성 | CPU와 메모리 사이 속도 차이 완충 |
| **주기억장치** | RAM | 빠름 | 중간 | 휘발성 | 실행 중인 프로그램과 데이터를 저장 |
| **보조기억장치** | HDD, SSD | 느림 | 매우 큼 | **비휘발성** | 전원 꺼져도 데이터 유지 |

---

# **캐시(Cache)**

- **정의**: 속도가 느린 장치 대신 빠른 장치에 데이터를 임시 저장하여 병목현상을 줄이는 저장소
- **예시**
    - CPU 캐시: CPU ↔ 메모리 사이
    - RAM: 보조기억장치(HDD/SSD) ↔ CPU 사이
    - 웹 브라우저 캐시: 서버 ↔ 사용자 브라우저 사이
- **캐싱 계층**: 빠른 계층과 느린 계층 사이에 놓여 병목을 줄이는 층

---

# **지역성(Locality)의 원리**

- **시간 지역성 (Temporal locality)**
    
    → 최근에 사용한 데이터는 다시 사용할 확률이 높다.
    
    예: for문에서 같은 변수를 반복 참조.
    
- **공간 지역성 (Spatial locality)**
    
    → 특정 데이터를 사용하면, 그 주변 데이터도 사용할 확률이 높다.
    
    예: 배열 순차 접근.
    

---

# **캐시 히트(Cache Hit) & 캐시 미스(Cache Miss)**

- **캐시 히트**: 캐시에 원하는 데이터가 있어 바로 사용 가능 → 빠름 (CPU 내부 버스 이용)
- **캐시 미스**: 캐시에 데이터 없음 → 주메모리/보조기억장치에서 가져옴 → 느림 (시스템 버스 이용)
- 성능 목표: **캐시 히트율**을 최대화.

---

# **캐시 매핑 (Cache Mapping)**

캐시에 데이터를 어떻게 배치할지 결정하는 방법.

1. **직접 매핑 (Direct Mapping)**
    - 메모리 블록 → 캐시의 특정 한 줄에만 배치
    - 구조 단순, 충돌(cache conflict) 많음
    - 예: 주소 % 캐시크기
2. **연관 매핑 (Associative Mapping)**
    - 어떤 메모리 블록도 캐시의 **어느 줄에도 저장 가능**
    - 유연하지만 탐색에 시간/비용 필요 (태그 전부 비교)
3. **집합 연관 매핑 (Set-Associative Mapping)**
    - 캐시를 **집합(Set)**으로 나눔
    - 메모리 블록은 특정 집합에만 매핑되고, 집합 안에서는 아무 줄에나 저장 가능
    - 직접 매핑과 연관 매핑의 절충안 → 실제 CPU 캐시에서 가장 많이 사용

---

# **웹 저장소**

| **구분** | **만료 여부** | **저장 단위** | **특징** |
| --- | --- | --- | --- |
| **쿠키** | 있음 (만료기한 설정) | 도메인 | 요청마다 서버로 전송됨 |
| **로컬 스토리지** | 없음 | 도메인 | 브라우저 종료 후에도 유지 |
| **세션 스토리지** | 없음 | 탭 단위 | 브라우저 탭 닫으면 삭제 |

---

# **데이터베이스 캐싱 계층**

- **DB 위에 캐시 계층 추가** → 성능 향상
- 대표 예: **Redis / Memcached**
    - DB에 자주 요청되는 데이터를 캐시에 저장
    - 읽기 부하는 캐시에서 처리 → DB 부하 감소
- 구조 예시:

```
클라이언트 → 캐시 계층(Redis) → DB(MySQL 등)
```

---

# **전체 요약**

- **레지스터 < 캐시 < 주기억장치 < 보조기억장치** 순으로 → 속도 ↓, 용량 ↑, 가격 ↓
- **캐시**는 빠른 장치와 느린 장치 사이의 병목을 줄이는 **중간 계층**
- **지역성 원리**로 캐시 성능을 설명 (시간/공간 지역성)
- **매핑 방식**: 직접 / 연관 / 집합 연관
- **웹 저장소**: 쿠키(만료 有, 서버전송), 로컬 스토리지(만료 無, 도메인 단위), 세션 스토리지(탭 단위)
- **DB 캐싱**: Redis 같은 메모리 DB를 계층으로 두어 속도 향상

---

## **0) 목표**

- **추상화**: 각 프로세스에 “거대한 연속 메모리”처럼 보이게 만들기
- **보호**: 프로세스 간, 유저/커널 간 접근 격리
- **효율**: 한정된 RAM을 최대한 활용(캐시/교체/프리페치/공유)

---

## **1) 가상 메모리와 주소 변환**

### **주소 공간과 MMU**

- **가상 주소(Logical)** ↔ **물리 주소(Physical)** 변환을 **MMU**가 담당.
- 프로세스 입장에선 0~최댓값까지 **연속적**인 공간처럼 보임(실제론 여기저기 흩뿌려짐).

### **페이징 기본**

- 메모리를 **고정 크기 페이지(page)** 단위로 쪼갬.
    - 예: 4KB, 16KB… (페이지가 커지면 TLB 적중↑, 내부 단편화↑ / 작으면 그 반대)
- 가상주소 = **[페이지 번호 | 페이지 내 오프셋]**

### **페이지 테이블(PTE)**

- 각 가상 페이지가 “어느 물리 프레임에 있는지”와 권한 비트 보관.
- PTE 주요 필드: **Present/Valid**, **R/W/X 권한**, **User/Supervisor**, **Accessed/Dirty**, **Global**, **NX** 등.
- **다단계 페이지 테이블**: 테이블을 트리화해 메모리 사용 절약.
- **역방향 페이지 테이블**: “물리 프레임 → 가상 소유자” 형태(대형 시스템에서 사용).

### **TLB (주소변환 캐시)**

- 페이지번호→물리프레임 매핑을 캐싱. 적중률이 곧 성능.
- 컨텍스트 스위칭 시 TLB 플러시 비용 큼 → **ASID/PCID**로 TLB 재사용 최적화.
- 코어 간 주소공간 변경 시 **TLB shootdown**(서로의 TLB 무효화) 비용 존재.

---

## **2) 수요 페이징 & 페이지 폴트**

### **수요 페이징(Demand Paging)**

- 실제로 **접근하는 순간**에만 페이지를 RAM에 적재(게으른 로딩).

### **페이지 폴트(Page Fault) 처리 흐름**

1. CPU가 해당 가상 페이지 미탐지 → **트랩** 발생.
2. 커널이 폴트 원인 확인(권한 위반인지, 단순 부재인지).
3. **파일-백드** 페이지면 디스크에서 읽어옴(또는 **익명/제로** 페이지면 0으로 채운 프레임 할당).
4. PTE 갱신(프레임 번호/권한/상태), TLB 갱신.
5. 폴트를 일으킨 명령 재실행.
- **Minor(Soft) Fault**: 이미 메모리에 있는데 매핑만 없었던 경우(빠름).
- **Major(Hard) Fault**: 디스크 I/O 필요(느림).
- **COW(Copy-on-Write)**: fork 이후 쓰기 시점에 복사 → 초기 메모리 공유로 성능/메모리 절약.

---

## **3) 스와핑/페이징 아웃 & 스래싱 방지**

### **스와핑/페이징 아웃**

- 메모리 압박 시 **덜 쓰이는 페이지**를 디스크로 내보냄(스왑 영역/페이지 파일).
- 백그라운드에서 **더티 페이지 쓰기**, **읽기 선행(프리페치)**, **클러스터링 I/O**로 최적화.

### **교체 알고리즘**

- 이론: **Optimal**(미래 참조 알고리즘) – 실제 불가, 비교 기준.
- 현실 근사: **LRU**, **Clock(Second-Chance)**, **NRU**, **Aging**, **LFU** 혼합 등.
- 핵심: **지역성**을 최대한 따라가게 유지.

### **워킹셋 & 스래싱**

- **워킹셋**: 일정 기간 실제로 필요한 페이지 집합.
- 워킹셋보다 RAM이 작아지면 **스래싱**(계속 폴트) → 성능 붕괴.
- 대응: 멀티프로그래밍 정도 낮추기, 우선순위 조정, 큰 작업 스케줄링 조정.

### **메모리 압력 대응**

- 과도한 압박 시: **OOM Killer/Jetsam** 등으로 희생양 프로세스 종료.
- **메모리 압력 신호**를 앱/서비스에 전달 → 캐시 해제·메모리 축소.

---

## **4) 메모리 할당(커널/유저)**

### **커널 할당기**

- **버디(Buddy) 시스템**: 페이지 프레임을 2의 거듭제곱 블록으로 분할/병합 → 빠른 할당/반납.
- **슬랩/SLUB**: 커널 객체(작은 고정 크기)를 캐싱 → 단편화↓, 캐시 지역성↑.
- **vmalloc**: 연속 가상/비연속 물리 매핑(큰/연속 요구시).

### **유저 공간 힙(malloc/free)**

- 내부 구조: **비슷한 크기별 빈 리스트**, **아레나**, **청크 병합** 등으로 단편화 완화.
- 전략: **first-fit / best-fit / next-fit** 혼합, **tcache** 등 최신 최적화.
- **내부 단편화**(블록 내부 남는 공간) vs **외부 단편화**(틈새 조각) 구분.

### **혼합 기법**

- **세그멘테이션**: 코드/데이터/스택 등 논리 단위로 나눔(보호/공유 용이, 외부 단편화).
- **페이징**: 고정 블록으로 단편화 완화(보호 단위는 거칠어짐).
- **세그먼트+페이징**: 장점 결합(대형 시스템/특수 OS).

---

## **5) 공유, 매핑, 제로-카피**

### **mmap**

- **파일-백드**: 파일 내용을 페이지캐시에 매핑, I/O를 메모리 접근처럼 수행.
- **익명 매핑**: 파일 없이 메모리만(스택/힙 유사 용도).
- 장점: I/O 시스템콜 횟수↓, **제로-카피**(커널/유저 복사 줄임), 프로세스 간 **공유 메모리** 구축 용이.

### **공유 메모리/IPC**

- 여러 프로세스가 같은 물리 프레임을 매핑 → **고속 IPC**.
- COW와 결합해 초기 공유, 쓰기 때만 복사.

### **DMA와 상호작용**

- **DMA**로 디바이스↔메모리 직접 전송(커널이 **핀드 페이지** 고정).
- 네트워크/스토리지 스택에서 **페이지 스플라이스/리사이클**로 복사 최소화.

---

## **6) 보호와 보안**

- **R/W/X 비트**로 실행/쓰기 분리(예: **W^X** 정책).
- **가드 페이지**로 스택 넘침 탐지.
- **ASLR**로 주소 무작위화(스택/힙/라이브러리/PIE).
- 유저/커널 **권한 비트**로 특권 경계 유지.

---

## **7) 고급 토픽(현업 최적화 포인트)**

- **Huge Pages**(예: 2MB, 1GB): TLB 적중률↑, 페이지 테이블/폴트↓. (대신 내부 단편화↑)
- **NUMA**: 코어-메모리 지역성 고려(“가까운 노드” 우선 할당).
- **Page Coloring**: 캐시 인덱스 충돌 줄이려 물리 프레임 색상화.
- **메모리 압축**: 압박 시 RAM 내에서 페이지 압축해 스왑 감소.
- **Overcommit/Lazy Allocation**: 먼저 주소만 약속(커밋), 실제 접근 때 물리 페이지 할당.
- **Prefetch/Advice**: madvise/프리페치 힌트로 I/O 선행.

---

## **8) 프로세스 메모리 레이아웃(상식 정리)**

```
[ 낮은 주소 ]
.text  (실행 코드, 실행 가능만)
.rodata(읽기 전용 상수)
.data  (초기화된 전역/정적)
.bss   (0 초기화 전역/정적)
heap   (위로 성장, 동적 할당)
...    (미매핑 가드)
stack  (아래로 성장, 콜프레임)
[ 높은 주소 ]
```

---

## **9) 모바일/임베디드 특이점 (짧게)**

- 폰/임베디드: 스왑 제한적/없거나 **메모리 압축 + 프로세스 강제 종료**(LMK/Jetsam)로 관리.
- 백그라운드 앱은 우선 정리 대상 → **메모리 경고 대응 코드** 중요.

---

## **10) 면접에 자주 나오는 포인트(Q&A식 요약)**

- **모드 전환 vs 컨텍스트 스위치**
    
    같은 태스크의 유저↔커널 이동 = 모드 전환 / 태스크 교체 = 컨텍스트 스위치.
    
- **Minor vs Major Fault**
    
    Minor: 이미 메모리에 있음(매핑만 필요) / Major: 디스크 I/O 필요.
    
- **LRU 못하는 이유**
    
    진짜 LRU는 과거 전부 기록 필요 → 비용 큼 → Clock/NRU 등 근사 사용.
    
- **COW 장점**
    
    fork 직후 대용량 복사 회피, 쓰기 시점에만 진짜 복사 → 메모리/시간 절약.
    
- **Huge Page 언제?**
    
    대용량 스캔/메모리 풋프린트 큰 서버, DB/ML 워크로드에서 유리(내부 단편화 주의).
    
- **스래싱 감지/대응**
    
    폴트율 급증, CPU 유휴·I/O 폭증 → 동시성 줄이기, 워킹셋 확보, 캐시 줄이기.
    

---

## **실무 팁(성능 이득이 큰 순)**

1. **접근 패턴을 “연속/배치”로**(공간/시간 지역성 극대화)
2. **mmap(파일-백드) + 페이지캐시** 적극 활용
3. **복사 최소화**: COW, zero-copy, DMA 고려
4. **구조체·배열 정렬/패딩**으로 캐시 미스 줄이기
5. **Huge Page/NUMA 바인딩**(해당 워크로드일 때만)
6. **메모리 압력 신호 대응 코드**(캐시 파지, 그래이스풀 다운사이즈)
